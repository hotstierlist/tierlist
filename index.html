<!DOCTYPE html>
<html>
<head>
	<title>HOTS EU Player List Explained</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/lipis/flag-icons@6.9.2/css/flag-icons.min.css" />
	<link rel="stylesheet" href="styles.css">
<style>
 body {
  background-color: #14121d;
  font-family: Arial, sans-serif;
  font-size: 13px;
  color: #efefef;
 }
  table {
    border-collapse: collapse;
	border-color: black;
    margin: 0 auto;
    font-family: Arial, sans-serif;
    font-size: 14px;
	/* table-layout: fixed; */
	width: 100%;
    text-shadow: 2px 2px 4px #000;
    border-collapse: collapse;
}
  
  th, td {
    border: 1px solid #000;
    padding: 2px;
    text-align: center;
    text-shadow: 0px 1px 2px #000000;
	color: #fff;
	font-size: 13px;
	font-weight: bold;
	height: 40px; /* set a fixed height for each table cell */
	width: 50px; /* set a fixed height for each table cell */
    border: 1px solid #1e1e1e;
    padding: 10px;
    white-space: pre-wrap;
    overflow: clip; /* Clips text that overflows the cell */
  }

  th {
    background-color: #14121d;
    color: #fff;
  }
  tr:nth-child(even) {
    background-color: #1c182c;
	padding: 0px;
  }

  tr:hover {
    background-color: #211835;
  }
  
  td.stier {
    background-color: #f65554;
    text-shadow: 2px 2px 0px #b71513;
    font-size: 25px;
    font-weight: bold;
	color: #fff;
}
  td.atier {
    background-color: #fea366;
	text-shadow: 2px 2px 0px #f26100;
    font-size: 25px;
    font-weight: bold;
	color: #fff;
}
  td.btier {
    background-color: #fff472;
	text-shadow: 2px 2px 0px #e4d307;
    font-size: 24px;
    font-weight: bold;
	color: #fff;
}
  td.ctier {
  	text-shadow: 2px 2px 0px #288c28;
    background-color: #6ffa6f;
    font-size: 24px;
    font-weight: bold;
	color: #fff;
}
  td.dtier {
  	text-shadow: 2px 2px 0px #1150b8;
    background-color: #66b0fa;
    font-size: 24px;
    font-weight: bold;
	color: #fff;
}
  td.ftier {
  	text-shadow: 2px 2px 0px #6416e0;
    background-color: #9756ff;
    font-size: 24px;
    font-weight: bold;
	color: #fff;
}
  td.fmtier {
  	text-shadow: 2px 2px 0px #8751f1;
    background-color: #d056ff;
    font-size: 24px;
    font-weight: bold;
	color: #fff;
}

	.info-box {
		width: 80%;
	}
	@media (max-width: 576px) {
		.info-box {
			width: 100%;
		}
	}

	table.info-box {
	text-align: left;
	width: 100%;
	
}
    td.legend{
	 margin: auto;
    text-align: left;
    text-shadow: 0px 0px 2px #000000;
	color: #fff;
	font-size: 13px;
	font-weight: normal;
	height: 2px; /* set a fixed height for each table cell */
	width: 100%; /* set a fixed height for each table cell */
    border-top: none;
	border-left: none;
	border-right: none;
    border-bottom: none;
    padding: 3px;
  }
    .legend tr:nth-child(even) {
    background-color: #14121d;
	border-top: none;
	border-left: none;
	border-right: none;
    border-bottom: none;
	padding: 0px;
	  height: 30px;
  }
    .legend th {
    background-color: #14121d;
	border-top: none;
	border-left: none;
	border-right: none;
    border-bottom: none;
	padding: 0px;
	height: 8px;
  }

  .legend tr:hover {
    background-color: #14121d;
	border-top: none;
	border-left: none;
	border-right: none;
    border-bottom: none;
  }

.description-cell {
  position: relative;
}

.description-cell::after {
  content: attr(data-description);
  position: absolute;
  top: -25px;
  left: 0;
  width: 100%;
  background-color: #14121d;
  color: #14121d;
  padding: 5px;
  font-size: 12px;
  text-align: center;
  opacity: 0;
  transition: opacity 0.3s;
}

.description-cell:hover::after {
  opacity: 1;
}

.tippy-content p {
	margin: 0px !important;
	padding: 0px !important;
}

.fw-bold {
	font-weight: bold;
}

.text-center {
	text-align: center;
}

.m-0 {
	margin: 0px !important;
}

.mb-1 {
	margin-bottom: 0.25rem !important;
}

.rounded-1 {
    border-radius: 3px !important;

}

</style>
</head>
<body>
<div align="center">	<img align="center" src="title.png"><br>
<h2>Select List</h2></div>
    <div class="image-container">
        <a href="1.html">
            <img src="category1.png" width="450" alt="Objective Player List">
        </a>  
		        <a href="2.html">
            <img src="category2.png" width="450" alt="Subjective Player List">
        </a>
    </div>
<div style="padding: 10px; margin: 20px" align="left">
<h1><i>Questions & Answers</i></h1>
<h3><i>Let's address some of the most frequent questions / misconceptions / concerns that have been raised:</i></h3>
<h3><i>"How did the player list come about?"</i></h3>
<ul>Sometime in 2022 BPRaiku & Gladius made a tierlist, consisting of and rating people they play with. Of course, as expected from such buffoons all their friends with whom they were 5-stacking with were put in S tier, and people who joined them only on occassionally, they badmouthed 24/7, ridiculed, criticized for their hero choice, even downright bullied were among the bottom places (including me). That was of course totally nonsensical and at best amusing, but still highlighted a broader question: is it possible to construct a player tier list that is impartial, reproducible, and fair - one that does not privilege friendships or penalize unfamiliarity? That question became the foundation of this Player List initiative.

The initial prototype was intentionally simple and relied primarily on win rate aggregation. While technically fair, it quickly proved insufficient due to its inability to account for context, variance, role impact, or behavioral factors. Recognizing these limitations, the methodology was iteratively expanded throughout 2023.

In the later stages, I collaborated with a close associate with a strong background in web development and applied AI systems. Importantly, this collaborator had no prior involvement with Heroes of the Storm, which ensured external objectivity and eliminated preconceived biases. Together, we designed a framework that leverages publicly available data - primarily from HeroesProfile - while applying structured weighting, role normalization, and behavior-aware interpretation.

The result is the current iteration of the Heroes of the Storm EU player list: a data-driven, bias-minimized evaluation system that prioritizes observable performance and consistency over personal affiliation. The dataset primarily covers both casual (QM,ARAM) and more competitive (Storm League,custom games) included where sufficient verifiable data exists.<br/>
The list is not intended to be definitive, but it is designed to be transparent, evidence-based, and uniformly applied - addressing the core shortcomings that motivated its creation in the first place.<br>
<li> As of July 10, 2024 it was separated into two different parts - One Objective/Stat-Based (the original idea) and One Subjective(my own experiences with said players)
</ul>

<h3><i>"Isn't it like a Burn Book?"</i></h3>
<ul>The comparison to a “burn book” misunderstands both the structure and purpose of this initiative. A burn book, as commonly understood, is private, selective, gossip-driven, and hidden from its subjects. This player list is the opposite. It has been publicly accessible from day one, transparently presented, and open to scrutiny.

Inclusion in the list is not the result of hearsay, personal vendettas, or behind-the-scenes commentary. Placement is driven by observable in-game behavior and publicly available performance data. No one is added arbitrarily, nor placed based on rumor or social dynamics. The inputs are actions taken in-game - communication patterns, reliability, consistency, and conduct over time.

The list is not intended to shame or ridicule. Its sole purpose is informational: to help members of the community make informed decisions about potential teammates. It provides context - how players tend to behave, what level of reliability they demonstrate, and whether past interactions suggest constructive or disruptive play. This allows others to decide whether to queue together, exercise caution, or give someone the benefit of the doubt.

Every player effectively starts from a neutral-positive baseline. Movement within the list - upward or downward - is determined entirely by demonstrated behavior and performance over time, not by personal relationships or opinions. In that sense, placement is not something done to players, but something shaped by their own actions.

As such, this Player List functions as a transparency tool, not a burn book.</ul>

<h3><i>"I Don't Like or Agree with your Player List. Now what?"</i></h3>
<ul>Every time someone disagrees with the player list, I can’t help but chuckle - because it inevitably reminds me of that classic “guy on the internet” moment:<br/>
<img src="guyoninternet.jpg" width="400"><br/>
To be clear, this isn’t a scientific, peer-reviewed paper. However, it is built on years of accumulated data - and I do mean years. Public statistics, performance records, and observed behavior over time don’t simply stop being relevant because they’re inconvenient. Numbers don’t lie.<br/>
I have a strong background in servers, databases, and data analysis, and a genuine appreciation for statistics and structured evaluation. A significant amount of time and research went into compiling this list. If I’m going to do something, I do it properly, accurately, and with intent. The goal here is simple: present the data as clearly and honestly as possible. What people choose to do with that information is entirely up to them.
If you disagree with the objective tier list, then you’re ultimately disagreeing with publicly available stats and recorded behavior - not with me. I’m not interested in arguing against data denial.
If you disagree with the subjective tier list, that’s perfectly fine as well - it’s an opinion, clearly labeled as such. Everyone is entitled to their own perspective, just as I have mine.
This page exists in service of the community. You don’t have to like it - but the information is here, transparent and openly presented, for anyone who wants to engage with it.</ul>

<h3><i>How objective do you believe your criteria and rankings are? How did you ensure that your personal biases did not overly influence the rankings?</i></h3>
<ul>This is an important question, and one I take seriously.
The primary goal of this initiative was to minimize personal bias as much as possible. To achieve that, I collaborated with an AI specialist who also has a competitive gaming background and understands core performance concepts such as KDA, KDR, APM, and MMR distributions. The intent was to translate commonly accepted performance indicators into a system that could be evaluated consistently and independently of personal relationships.
<br/>
Over time, the model evolved. Early iterations relied on limited indicators such as signature heroes; later versions incorporated a broader and more granular set of metrics. Despite this, the common criticism remains that the results are “just opinion.” That criticism misses the point. The purpose of the system is to remove my opinion from the evaluation layer and instead function as a third-party observer - focused on events that actually occurred, are verifiable, and are independent of personal like or dislike.
<br/>
Several deliberate safeguards were used to counter bias. First, rankings were generated before any social descriptors were written, ensuring that narrative did not influence numerical placement. Second, the system was tested against my own expectations, and in multiple cases the results contradicted them - both positively and negatively. Those outcomes were accepted rather than adjusted.
<br/>
As an additional bias check, I previously ran a small social experiment by intentionally misrepresenting rankings: placing strong players lower than warranted and average players higher than warranted. The outcome was revealing. Both groups responded positively - those overrated were pleased, and those underrated were unconcerned. This reinforced a key insight: emotional reactions to rankings are not reliable indicators of accuracy, which further justified separating evaluation from sentiment. Lastly, I've had multiple widely regarded community members give me their take/feedback/input, which has also been taken into account.
Absolute objectivity is unattainable in any human-designed system. However, by constraining inputs to observable data, enforcing consistent weighting, and accepting results even when they conflict with personal perception, the rankings are as objective and reproducible as the available data allows.</ul>

<h3><i>Me or a friend of mine appear in the player list, but we only troll QM/ARAM so those stats aren't an accurate representation</i></h3>
<ul>This is a valid concern and one that has been explicitly accounted for in the evaluation model. Casual modes such as Quick Match and ARAM are known to produce high statistical noise due to experimentation, limit-testing, off-role play, and intentional non-optimal behavior.<br/>
As a result, Ranked (Storm League) performance - particularly Solo Queue data - is weighted significantly higher than QM or ARAM metrics when determining overall placement. If a player demonstrates stronger statistical performance in Ranked than in casual modes, the system treats QM/ARAM data as low-signal and minimizes its impact accordingly.<br/>
This weighting approach ensures that players who primarily engage in competitive environments - such as scrims, customs, tournaments, ladder grinding, Ravencourt etc. are not penalized for treating casual modes casually. For these players, QM and ARAM function as non-evaluative datasets unless their performance in Ranked corroborates the same trends.<br/>
In practical terms, this acts as a statistical override: consistent, positive Ranked performance supersedes inflated variance from casual play. Players whose Ranked metrics reflect higher discipline, decision-making, and impact are therefore still represented accurately, regardless of how unseriously they treat QM or ARAM.</ul>

<h3><i>Some players play only in 5 stacks so their stats are artificially inflated statistics compared to others. Doesn't this lead to a misleading representation of player statistics?</i></h3>
<ul>Some players primarily play in 5-stacks, which can inflate their statistics. This concern is explicitly addressed in the evaluation methodology.
The vast majority of metrics are derived from Solo Queue Storm League / Hero League games, which provide the cleanest signal of individual performance. Duo (2-stack) data is used secondarily as a comparative reference, while Trio (3-stack) data is only considered in limited cases.<br/>
Statistics generated from full 5-stacks are intentionally excluded from core skill evaluation due to their inherently inflated and non-transferable nature. Coordinated play, voice communication, and pre-established synergy introduce external variables that significantly distort individual performance metrics.<br/>
If a player lacks sufficient Solo or Duo data and exclusively plays in 5-stacks, their skill rating is marked as Not Available rather than inferred or estimated. This avoids misrepresentation and prevents unfair comparisons.
Win rate is also not treated as a primary indicator of skill once it exceeds a baseline threshold of roughly 50%. A solo player with a 53% win rate can therefore rank higher than a 5-stack player with a 90%+ win rate, as the former demonstrates individual impact in an uncontrollable environment.

Overall, the objective player list is designed to minimize structural bias and maximize fairness by isolating individual performance wherever possible.
.</ul>

<h3><i>Have you considered how the tier list might be perceived by your friends?</i></h3>
<ul>I’ve considered that perception, and the approach remains the same regardless of personal relationships. The methodology prioritizes evidence over sentiment. Assumptions are questioned, claims require data, and conclusions are adjusted when better information is presented. Being proven wrong is not a negative outcome - it’s part of refining the model.<br/>
Personal feelings are deliberately separated from evaluation. The goal is not to judge character or diminish anyone’s value as a friend, but to assess in-game performance and behavior as objectively as possible. Every player effectively starts from a neutral baseline and moves up or down based on observed actions and publicly available data.<br/>
A lower placement is not a statement of personal worth, nor does it affect the respect I have for anyone. In fact, applying the same standards universally - including to friends - reinforces fairness and consistency. I value transparency, accountability, and long-term improvement, both in games and in relationships.<br/>
Quality matters more than quantity, and honest evaluation - when done consistently and without favoritism - is part of maintaining that standard.</ul>

<h3><i>What are you hoping to achieve with the player list and what future does it have?</i></h3>
<ul>The motivation behind this player list is straightforward. If a resource like this had existed when I started playing Heroes of the Storm again, it would have saved significant time, avoided unnecessary friction and likely prevented a few misguided online associations. I learned - often through trial and error - that not every player operates in good faith. Warnings without evidence are easy to dismiss, and giving unlimited benefit of the doubt can come at a cost.<br/>
This project exists to provide clarity, transparency, and context, grounded in observable behavior and publicly available data. It is not driven by favoritism, grudges, or personal disputes, but by consistency and documentation. The intent is to offer others the perspective I wish I had earlier, so decisions about who to queue with are informed rather than blind.<br/>
As for its future, the list is effectively complete. The objective was never to maintain an evolving or permanent project, but to create a useful reference. At this point, only minimal updates are expected, if any..</ul>

<h3><i>Did you compare your rankings to any other forms of relationship assessment or feedback?</i></h3>
<ul>Yes, but the available external reference points are limited. The primary sources are HeroesProfile and in-game account statistics, both of which have known limitations and inaccuracies. As a result, direct cross-validation options are constrained.
Rather than relying on any single third-party metric, the evaluation process effectively functions as a custom, behavior-adjusted performance model. Relevant statistics are categorized by signal quality (positive vs. negative indicators), weighted accordingly, and evaluated in aggregate. AI is used to process these inputs consistently, identify patterns, and reduce individual bias in interpretation.
While this is not a replacement for an official MMR system, the resulting output operates as a proxy skill-and-reliability index, designed to be more reflective of real teammate value than legacy tools such as HeroesProfile or the now-defunct Hotslogs. The emphasis is not on absolute ranking accuracy, but on relative consistency, accountability, and observed impact over time within the limits of available data.</ul>

<h3><i>Don't you feel bad exposing people?</i></h3>
<ul>It’s interesting how no one questions the countless positive or complimentary comments - only the few critical ones draw attention. When someone receives praise or a good ranking, it’s often ignored or dismissed. But as soon as something negative (that actually happened) is being shared/revealed, suddenly it's controversial or “too far.”
Let’s be clear - I don’t expose, doxx, manipulate, or harass anyone. I document what actually happens: things said or done in-game, in Discord, or in public chats - events others have witnessed, screenshots I’ve saved, and patterns anyone paying attention could recognize. I don’t invent narratives - I observe and reflect them.
And if someone really believes placements are meaningless, then why get upset? If someone placed me in F-tier on their list, I wouldn’t care. Why? Because I know who I am and what I’m capable of. The irony is, the loudest complaints come from those who are unhappy with their own placement - yet those same people often add the top-ranked players to ask: “Yo, how did you get rated so highly?” The answer? “Nothing. I just played the game.”
People place themselves on the list through their own behavior. What we do here is simply observe, take notes, and present what’s already out there, quite easy to verify.</p></ul>

<h3><i>How have the relationships with the people in different tiers evolved?</i></h3>
<ul>I'll repeat, I'm all about quality over quantity. I believe that everyone can change and improve their ranking and their socials. I believe good communication can solve any problem. We were all dumb at some point, I'm dumb about a great many things now that in the future I'll understand better and that's what makes us human. So yes, I believe there are only two or three people in that entire player list that are absolutely beyond reach and do not have any redeemable qualities. Everyone else can impress(or disappoint), but as far as playing with people from different tiers of the Objective Player list - it doesn't affect me, simply because I still try to be the best, most consistent teammate I can be for my teammates regardless of who I play with. </ul>

<h3><i>Do you regret making the Player list?</i></h3>
<ul>Do I regret creating the player list? At times, yes - particularly in the early stages. Before the list was clearly separated into objective and subjective components, the initial version was still evolving and was often misunderstood or taken out of context. That period attracted a disproportionate amount of criticism, much of it from people reacting emotionally or projecting expectations that the project was never meant to fulfill.<br/>
No matter how carefully intent is explained or methodology refined, some individuals will always be dissatisfied - often for reasons unrelated to accuracy or fairness. That early phase was rough, but it also highlighted the need for clearer structure, better communication, and stronger separation between data-driven evaluation and personal experience.
The goal was never to insult, shame, or attack anyone. The list exists as a transparent, evidence-based resource intended to help the community make more informed decisions about potential teammates. Most players on the list are people you will inevitably encounter in your own games, and the intent has always been to provide context based on consistent behavior and observable performance - not drama or personal disputes.<br/>
Over time, as more data accumulated and patterns stabilized, perceptions began to shift. As the list aged, its accuracy improved, and many of the same people who initially criticized it later acknowledged that the assessments aligned with their own experiences. Hearing variations of “you were right” was not the objective - but it reinforced that long-term behavior tends to validate itself when evaluated consistently.<br/>
Today, I don’t regret making it. While it is not perfect, the project has largely achieved its purpose: helping others avoid the same mistakes I made early on, identifying reliable teammates, flagging disruptive patterns, and improving the overall experience for players who simply want to enjoy the game - casually or competitively - without unnecessary conflict.
The early backlash was part of the cost of building something transparent. The long-term appreciation is the proof that it was worth doing.</ul>

<h3><i>Are you being too harsh on people you have personal distaste for?</i></h3>
<ul>No. The AI-assisted rankings were designed specifically to reduce confirmation bias, not reinforce it. In practice, the results frequently contradicted my initial assumptions. Some players I had underestimated ranked higher than expected, while others I assumed were strong underperformed when evaluated against the data. This is not a flaw of the system - it is the intended outcome of evidence-driven analysis.<br/>
The methodology is adaptive. When new or stronger evidence becomes available, conclusions are revised accordingly. Data & knowledge are used to challenge perception, not validate preconceived opinions.
The accompanying social or behavioral summaries are based on documented interactions and recurring, observable patterns over time. Whether these descriptions are perceived as “harsh” is subjective; they are not expressions of personal distaste, but reflections of consistent behavior. Dismissing them as harsh often sidesteps engagement with the underlying evidence.<br/>
A consistent pattern among top-ranked players further reinforces this approach. When asked what they did to achieve their placement, the answer is invariably the same: nothing exceptional. They avoided trolling and griefing, maintained accountability, communicated appropriately, and treated others with basic respect. In practice, simply being a reliable and constructive teammate already places a player well above average.</ul>

<h3><i>When was this last Updated?</i></h3>
<ul>Last Update: 29 December 2025</ul>
</div>


<div align="center">
<h1><i>“Manipulation is when they blame you for reacting to their toxic behavior, but not addressing their actions that undermined, diminished & disrespected you in the first place.”</h1>
</div>
<link rel="stylesheet" href="https://hotstierlist.github.io/tierlist/translucent.css"/>
<script src="https://unpkg.com/@popperjs/core@2"></script>
<script src="https://unpkg.com/tippy.js@6"></script>
<script>
tippy('.tooltip', {
	allowHTML: true,
	hideOnClick: false,
	theme: 'translucent',
	placement: 'auto',	
	duration: 150,
});
</script>
</body>
</html>